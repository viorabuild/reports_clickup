Metadata-Version: 2.4
Name: clickup-gpt-agent
Version: 0.1.0
Summary: Automation agent that analyzes ClickUp tasks with GPT and writes recommendations.
Author: Codex
Requires-Python: >=3.10
Description-Content-Type: text/markdown
Requires-Dist: httpx>=0.27.0
Requires-Dist: openai>=1.13.3
Requires-Dist: pydantic>=2.6.4
Requires-Dist: pydantic-settings>=2.2.1
Requires-Dist: python-dotenv>=1.0.1
Requires-Dist: tenacity>=8.2.3
Provides-Extra: dev
Requires-Dist: pytest>=7.4; extra == "dev"
Requires-Dist: ruff>=0.3; extra == "dev"

# ClickUp Reports Agent

Агент помогает быстро пройтись по задачам в ClickUp, попросить локальную модель оценить качество исполнения и скорость, а затем сохранить оценки и комментарии прямо в карточке. Его можно запускать вручную или по расписанию, чтобы закрывать хвосты в конце дня.

## Что делает агент

1. Загружает новые или активные задачи по выбранному списку либо пространству.
2. Формирует понятный промпт с описанием задачи и историей изменений.
3. Отправляет промпт в LM Studio с моделью `qwen3-vl-4b`, получая скорость, качество и короткое пояснение.
4. Записывает оценки в кастомные поля, добавляет комментарий в задачу.
5. При необходимости переводит карточку в финальный статус (например, «Закрыта»).

## Зачем это нужно

- **Единые стандарты** — оценки выдаёт одна модель, поэтому подход к задачам становится прозрачным.
- **Экономия времени** — руководитель получает сводку качества без ручного проставления баллов.
- **Готовность к отчётам** — оценки и комментарии лежат в карточке, их легко выгружать в отчётность.

## Как устроен процесс

```text
ClickUp → (fetch) → Агент → (prompt) → LM Studio → (scores) → Агент → ClickUp
```

- Можно ограничить задачи по статусам (например, обрабатывать только «Сделано»).
- Агент ведёт историю оценок и не превышает лимит, который вы задаёте.
- Режим `--dry-run` покажет планируемые действия без изменений в аккаунте.

## Требования

- Python 3.10+
- Активный токен ClickUp API с правами чтения и записи задач
- Локально запущенный LM Studio HTTP-сервер (по умолчанию `http://127.0.0.1:1234`) с моделью `qwen/qwen3-vl-4b`

## Быстрый старт

1. Создайте виртуальное окружение и установите зависимости:

   ```bash
   python -m venv .venv
   source .venv/bin/activate
   pip install -r requirements.txt
   ```

2. Скопируйте `.env.example` (если он есть) или создайте `.env` вручную.
3. Заполните переменные окружения (см. таблицу ниже).
4. Запустите агент:

   ```bash
   python -m src.clickup_agent
   ```

5. Проверьте комментарии и обновлённые поля в ClickUp.

## Настройка окружения

| Переменная | Что она делает |
| --- | --- |
| `CLICKUP_API_TOKEN` | Личный токен ClickUp. Можно получить в настройках профиля. |
| `CLICKUP_LIST_ID` | ID списка, из которого брать задачи. Заполняйте **или** `CLICKUP_SPACE_ID`. |
| `CLICKUP_SPACE_ID` | ID пространства, если нужно обработать все списки внутри. |
| `CLICKUP_SPEED_FIELD_ID` | ID кастомного поля для оценки скорости. |
| `CLICKUP_QUALITY_FIELD_ID` | ID кастомного поля для оценки качества. |
| `CLICKUP_TARGET_STATUSES` | (опционально) Список статусов через запятую, которые стоит обрабатывать. |
| `CLICKUP_AUTO_CLOSE_STATUSES` | (опционально) Статусы, из которых задачу можно перевести в закрытие. |
| `CLICKUP_CLOSED_STATUS` | (опционально) Имя финального статуса, куда переводим после оценки. Работает вместе с предыдущим параметром. |
| `CLICKUP_MAX_TASKS` | (опционально) Лимит задач за один запуск. По умолчанию берём все. |
| `LM_STUDIO_BASE_URL` | Адрес LM Studio. Если запускаете локально — оставьте значение по умолчанию. |
| `LM_STUDIO_MODEL` | Имя модели в LM Studio. По умолчанию `qwen/qwen3-vl-4b`. |
| `LM_TEMPERATURE` | Температура генерации. Чем ниже, тем стабильнее ответы. Значение по умолчанию — `0.2`. |
| `ASSESSMENT_HISTORY_LIMIT` | (опционально) Сколько последних записей об оценках хранить. |
| `ASSESSMENT_HISTORY_PATH` | (опционально) Путь к файлу, где хранится история оценок. |

> **Важно:** укажите только один источник задач — `CLICKUP_LIST_ID` или `CLICKUP_SPACE_ID`. Если задать оба или не задать ни одного, агент не стартует.

Пример `.env`:

```env
CLICKUP_API_TOKEN=pk_ваш_clickup_token
# CLICKUP_LIST_ID=123456789
CLICKUP_SPACE_ID=987654321
CLICKUP_SPEED_FIELD_ID=custom_скорость
CLICKUP_QUALITY_FIELD_ID=custom_качество
```

## Запуск и полезные флаги

```bash
# стандартный запуск
python -m src.clickup_agent

# посмотреть, что произойдёт, без записи в ClickUp
python -m src.clickup_agent --dry-run

# ограничить количество задач
python -m src.clickup_agent --max-tasks 3
```

- `--dry-run` — идеален для первой проверки конфигурации.
- `--max-tasks` — помогает протестировать работу агента без изменения переменных окружения.

## Что происходит при запуске

1. Агент получает список задач из ClickUp с учётом выбранных фильтров.
2. Формирует промпт с описанием задачи, чеклистами и историей комментариев (где доступно).
3. Обращается к LM Studio и получает структуру вида:

   ```json
   {
     "speed_score": 4,
     "quality_score": 5,
     "comment": "Короткий вывод по задаче"
   }
   ```

4. Записывает оценки в кастомные поля и добавляет комментарий в карточку.
5. Переводит задачу в финальный статус, если она соответствует условиям автозакрытия.

## Структура проекта

- `src/clickup_agent/config.py` — загрузка и валидация конфигурации.
- `src/clickup_agent/clickup.py` — обёртка над ClickUp API (чтение/обновление задач).
- `src/clickup_agent/lm_studio.py` *(или аналогичный модуль)* — взаимодействие с LM Studio.
- `src/clickup_agent/orchestrator.py` — основной сценарий обработки.
- `src/clickup_agent/__main__.py` — CLI-входная точка (`python -m src.clickup_agent`).
- `reports/` — история оценок, если включено логирование в файл.

## Советы по эксплуатации

- Для отладки поставьте `CLICKUP_MAX_TASKS=3`, чтобы не грузить модель.
- Если хотите тонко настроить выборку задач — добавьте фильтр `CLICKUP_TARGET_STATUSES`.
- Настраивайте уровень логирования через переменную `PYTHONLOGGING` или прямо в конфигурации.
- Планируйте запуск через cron, GitHub Actions или любой другой планировщик, если нужны регулярные проверки.

## Безопасность и наблюдаемость

- Храните токены только в `.env` или секрет-хранилищах.
- Не логируйте чувствительные данные — модели не обязательно знать приватные комментарии.
- При первом запуске на реальных задачах используйте `--dry-run` и убедитесь, что поля и статусы настроены корректно.
- Следите за логами: в них отображаются ошибки сети, отсутствие полей и прочие проблемы с конфигурацией.

## Идеи для развития

- Поддержка нескольких моделей и динамический выбор промптов.
- richer отчёты по задачам и сотрудникам (e-mail, Telegram, Notion).
- Вебхуки для быстрой реакции на изменение статуса задач.

Если возникли вопросы или хочется расширить функциональность — заводите issue или пишите в личку, буду рад помочь.
